import json
import re
from typing import List, Dict
from pydantic import Field

from app.tool.base import BaseTool, ToolResult
from app.llm import LLM
from app.logger import logger
from app.tool.web_search import WebSearch

class TopicResearchTool(BaseTool):
    name: str = "topic_research"
    description: str = """
    Uses an LLM with search capabilities to generate an initial research summary and, most importantly, 
    generate a list of high-quality reference URLs for further deep scraping.
    """
    parameters: dict = {
        "type": "object",
        "properties": {
            "topic": {
                "type": "string",
                "description": "The research topic or user query."
            }
        },
        "required": ["topic"]
    }

    llm: LLM = Field(default_factory=LLM, exclude=True)
    # æˆ‘ä»¬ä¾ç„¶éœ€è¦ç»™ LLM ä¸€ä¸ªæœç´¢å·¥å…·ï¼Œè®©å®ƒèƒ½è”ç½‘æŸ¥åˆ°é“¾æ¥
    search_tool: WebSearch = Field(default_factory=WebSearch, exclude=True)

    async def execute(self, topic: str) -> ToolResult:
        logger.info(f"ğŸ§  Researching topic: {topic}")

        # 1. å…ˆè®©æœç´¢å·¥å…·è·‘ä¸€æ¬¡ï¼Œè·å–åŸå§‹ç´ æç»™ LLM
        # æ³¨æ„ï¼šå¦‚æœä½ çš„ LLM (å¦‚ Gemini Pro) åŸç”Ÿè‡ªå¸¦è”ç½‘ï¼Œå¯ä»¥è·³è¿‡è¿™ä¸€æ­¥ç›´æ¥é—®ã€‚
        # ä½†ä¸ºäº†é€šç”¨æ€§ï¼Œæˆ‘ä»¬è¿™é‡Œå…ˆæ‰‹åŠ¨æœä¸€ä¸‹ï¼ŒæŠŠä¸Šä¸‹æ–‡å–‚ç»™ LLMã€‚
        search_result = await self.search_tool.execute(query=topic, num_results=10)
        
        # 2. æ„å»º Promptï¼Œå¼ºåˆ¶ LLM è¾“å‡º JSON æ ¼å¼çš„é“¾æ¥åˆ—è¡¨
        prompt = f"""
        You are an expert researcher.
        I have a topic: "{topic}".
        
        Here are some search results I found:
        {search_result.output}

        **YOUR TASKS:**
        1. Analyze the search results and identify the 10-15 BEST articles that contain rich details (images, trends, data).
        2. Briefly explain why these articles are relevant.
        3. **CRITICAL**: Output the exact URLs of these best articles in a strict JSON list format at the very end.

        **OUTPUT FORMAT:**
        [Analysis text...]

        URL_LIST_START
        ["https://best-site.com/article1", "https://another-site.com/article2"]
        URL_LIST_END
        """

        # 3. è¯¢é—® LLM
        messages = [
            {"role": "user", "content": prompt}
        ]
        response = await self.llm.ask(messages)
        
        # 4. æå–é“¾æ¥ (Regex)
        urls = []
        try:
            # åŒ¹é… URL_LIST_START å’Œ URL_LIST_END ä¸­é—´çš„å†…å®¹
            match = re.search(r'URL_LIST_START(.*?)URL_LIST_END', response, re.DOTALL)
            if match:
                json_str = match.group(1).strip()
                # æ¸…ç†å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
                json_str = json_str.replace("```json", "").replace("```", "")
                urls = json.loads(json_str)
            else:
                # å¤‡ç”¨æ–¹æ¡ˆï¼šå°è¯•æ‰¾ä»»ä½•çœ‹èµ·æ¥åƒ JSON åˆ—è¡¨çš„ä¸œè¥¿
                match = re.search(r'\[\s*".*?"\s*\]', response, re.DOTALL)
                if match:
                    urls = json.loads(match.group(0))
        except Exception as e:
            logger.error(f"Failed to parse URLs from LLM response: {e}")
            logger.debug(f"LLM Response was: {response}")

        if not urls:
            return ToolResult(error="LLM analyzed the topic but failed to return a valid JSON list of URLs.")

        logger.info(f"âœ… LLM generated {len(urls)} target URLs: {urls}")
        
        # ç›´æ¥è¿”å› URL åˆ—è¡¨çš„ JSON å­—ç¬¦ä¸²ï¼Œæ–¹ä¾¿ SmartScraper è¯»å–
        return ToolResult(output=json.dumps(urls))
    
